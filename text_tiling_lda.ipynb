{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c36d7391-d3e0-497b-aee0-0cae70d3c113",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import MeCab\n",
    "import re\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.decomposition import LatentDirichletAllocation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8f5d8250-3b76-4627-a138-7df17eb67140",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 分かち書きの中で使うオブジェクト生成\n",
    "tagger = MeCab.Tagger(\"-d /usr/local/lib/mecab/dic/mecab-ipadic-neologd\")\n",
    "# ひらがなのみの文字列にマッチする正規表現\n",
    "kana_re = re.compile(\"^[ぁ-ゖ]+$\")\n",
    "\n",
    "\n",
    "def mecab_tokenizer(text):\n",
    "    # テキストを分かち書きする関数を準備する\n",
    "    parsed_lines = tagger.parse(text).split(\"\\n\")[:-2]\n",
    "    surfaces = [l.split('\\t')[0] for l in parsed_lines]\n",
    "    features = [l.split('\\t')[1] for l in parsed_lines]\n",
    "    # 原型を取得\n",
    "    bases = [f.split(',')[6] for f in features]\n",
    "    # 品詞を取得\n",
    "    pos = [f.split(',')[0] for f in features]\n",
    "\n",
    "    # 各単語を原型に変換する\n",
    "    token_list = [b if b != '*' else s for s, b in zip(surfaces, bases)]\n",
    "\n",
    "    # 名詞,動詞,形容詞のみに絞り込み\n",
    "    target_pos = [\"名詞\", \"動詞\", \"形容詞\"]\n",
    "    token_list = [t for t, p in zip(token_list, pos) if p in target_pos]\n",
    "    # アルファベットを小文字に統一\n",
    "    token_list = [t.lower() for t in token_list]\n",
    "    # ひらがなのみの単語を除く\n",
    "    token_list = [t for t in token_list if not kana_re.match(t)]\n",
    "    # 数値を含む単語も除く\n",
    "    token_list = [t for t in token_list if not re.match(\"\\d\", t)]\n",
    "    return \" \".join(token_list)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "e94bc261-03bb-48c0-b2fe-4b9282761703",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def calc_vectors(utterances, n_components):\n",
    "#     tokenized_utterances = [mecab_tokenizer(utt) for utt in utterances]\n",
    "#     # テキストデータをBOW形式に変換する\n",
    "#     tf_vectorizer = CountVectorizer(\n",
    "#         token_pattern='(?u)\\\\b\\\\w+\\\\b',\n",
    "# #         max_df=0.90,\n",
    "# #         min_df=10,\n",
    "#     )\n",
    "#     tf = tf_vectorizer.fit_transform(tokenized_utterances)\n",
    "#     # LDAのモデル作成と学習\n",
    "#     lda = LatentDirichletAllocation(n_components=n_components)\n",
    "#     return lda.fit_transform(tf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "f51ad1d1-9f82-4a26-bed2-7cd09d7487fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectors = calc_vectors(\n",
    "    [' これから本番の収録を開始します。', ' はじめまして・・私の名前は「メイ」です。「対話の実験」の手伝いをしています。今日はよろしくお願いします。', 'よろしくお願いします', ' きょうはここまでなにで来られましたか?乗り物は乗りましたか?', 'そうですね 電車で 来て歩いて来ました', ' ここに来るまで迷いませんでしたか・・', 'ここに来るまでは人に教えてもらったので 迷いませんでした', ' 大学の中でも、たてものが奥にあるので、みなさん来るのが「たいへん」でしたとよく言われます・・', '(F あー)そうなんですか 確かに奥にありました', ' きょうは来ていただいてありがとうございます!', ' それでは「食べ物」について話しましょう!', '(F はい)', ' 甘いものはお好きですか?', '甘いものは洋菓子じゃなくて和菓子のほうが好きですね', ' 普段はどこであまいものを買いますか?', '普段はいやあコンビニが多いですね', ' 和菓子はどんなものですか'],\n",
    "    n_components=2\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "beba7e17-28df-47da-942d-5b0cfcca315f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.13091425, 0.86908575],\n",
       "       [0.05793763, 0.94206237],\n",
       "       [0.25567502, 0.74432498],\n",
       "       [0.86907345, 0.13092655],\n",
       "       [0.89724667, 0.10275333],\n",
       "       [0.83040325, 0.16959675],\n",
       "       [0.89712678, 0.10287322],\n",
       "       [0.202934  , 0.797066  ],\n",
       "       [0.12892683, 0.87107317],\n",
       "       [0.74627338, 0.25372662],\n",
       "       [0.82643011, 0.17356989],\n",
       "       [0.25576428, 0.74423572],\n",
       "       [0.83002433, 0.16997567],\n",
       "       [0.89749754, 0.10250246],\n",
       "       [0.17251835, 0.82748165],\n",
       "       [0.12985237, 0.87014763],\n",
       "       [0.74505098, 0.25494902]])"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "d300bf6d-c539-453c-897b-fe07fe429428",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.spatial import distance\n",
    "import MeCab\n",
    "import numpy as np\n",
    "\n",
    "# def calc_similarity(topic1, topic2, window_size=5):\n",
    "def calc_similarity(topic1, topic2, n_components=5):\n",
    "    # テキストデータをBOW形式に変換する\n",
    "    tf_vectorizer = CountVectorizer(\n",
    "        token_pattern='(?u)\\\\b\\\\w+\\\\b',\n",
    "#         max_df=0.90,\n",
    "#         min_df=10,\n",
    "    )\n",
    "    lda_vectorizer = LatentDirichletAllocation(n_components=n_components)\n",
    "    \n",
    "    def train(utterances):\n",
    "        tokenized_utterances = [mecab_tokenizer(utt) for utt in utterances]\n",
    "        tf = tf_vectorizer.fit_transform(tokenized_utterances)\n",
    "        # LDAの学習\n",
    "        lda_vectorizer.fit(tf)\n",
    "    \n",
    "    def predict(utterance):\n",
    "        tokenized_utterance = mecab_tokenizer(utterance)\n",
    "        tf = tf_vectorizer.transform([tokenized_utterance])\n",
    "        return lda_vectorizer.transform(tf)\n",
    "    \n",
    "    train(topic1 + topic2)\n",
    "    \n",
    "    vec1 = predict(' '.join(topic1))\n",
    "    vec2 = predict(' '.join(topic2))\n",
    "    \n",
    "#     vectors = calc_vectors(topic1 + topic2, n_components=n_components)\n",
    "#     n1 = len(topic1)\n",
    "#     vec1 = np.mean(vectors[:n1], axis=0)\n",
    "#     vec2 = np.mean(vectors[n1:], axis=0)\n",
    "\n",
    "#     vec1 = np.mean(vectors[n1-window_size:n1], axis=0)\n",
    "#     vec2 = np.mean(vectors[n1:n1+window_size], axis=0)\n",
    "    return 1 - distance.cosine(vec1, vec2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "97c74a80-d428-4c3f-89f8-6ee747bca065",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.1516435019040483"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "calc_similarity(['コンサートとかには行きますか？'], ['コンサートは行かないですけど、映画とかは好きですね'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "980a3853-a7ac-4617-8f96-0ce1677d0154",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8133555761682684"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "calc_similarity(['コンサートとかには行きますか？'], ['コンサートは行かないですけど、映画とかは好きですね', '映画といえば、閃光のハサウェイは見ましたか？'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "41d3f189-3d81-48aa-ba7b-3d601080f35a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.20015429879330116"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "calc_similarity(['コンサートとかには行きますか？'], ['織田信長の野望'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "8859d6d6-2f3f-49f5-b12d-16d3b00d40c6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.20015429879323132"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "calc_similarity(['豊臣秀吉の狙いはなんだったのか？'], ['織田信長の野望'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "id": "8615de26-4e6b-4b9f-a911-1974ce789ab0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def topic_generator(text_gen, threshold=0.3, max_utterances=50, min_utterances=10, delay=3, n_components=5):\n",
    "    cur_topic = [next(text_gen)]\n",
    "    \n",
    "    for text in text_gen:\n",
    "        similarity = calc_similarity(cur_topic[:-delay], cur_topic[-delay:] + [text], n_components=n_components)\n",
    "        if (\n",
    "            similarity < threshold\n",
    "            or len(cur_topic) >= max_utterances\n",
    "        ) and len(cur_topic) >= min_utterances + delay:\n",
    "            yield cur_topic[:-delay]\n",
    "            cur_topic = cur_topic[-delay:] + [text]\n",
    "        else:\n",
    "            cur_topic.append(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "id": "dc04d013-6dc1-435c-abe0-007d68f8b824",
   "metadata": {},
   "outputs": [],
   "source": [
    "import jsonlines\n",
    "import unicodedata\n",
    "import re\n",
    "\n",
    "def transcript_generator(path):\n",
    "    with jsonlines.open(path) as reader:\n",
    "        for data in reader:\n",
    "            yield preprocess_transcript(data['transcript'])\n",
    "\n",
    "def preprocess_transcript(transcript):\n",
    "    transcript = unicodedata.normalize('NFKC', transcript)\n",
    "    transcript = transcript.replace('|', ' ')\n",
    "    transcript = re.sub(r'\\(.+\\)', '', transcript)\n",
    "    return transcript"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "id": "b40f63ed-e4d8-4313-b774-f55f98b3cc0e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[' これから本番の収録を開始します。', ' はじめまして・・私の名前は「メイ」です。「対話の実験」の手伝いをしています。今日はよろしくお願いします。', 'よろしくお願いします', ' きょうはここまでなにで来られましたか?乗り物は乗りましたか?', 'そうですね 電車で 来て歩いて来ました', ' ここに来るまで迷いませんでしたか・・', 'ここに来るまでは人に教えてもらったので 迷いませんでした', ' 大学の中でも、たてものが奥にあるので、みなさん来るのが「たいへん」でしたとよく言われます・・', 'そうなんですか 確かに奥にありました', ' きょうは来ていただいてありがとうございます!', ' それでは「食べ物」について話しましょう!'] \n",
      "\n",
      "['', ' 甘いものはお好きですか?', '甘いものは洋菓子じゃなくて和菓子のほうが好きですね', ' 普段はどこであまいものを買いますか?', '普段はいやあコンビニが多いですね', ' 和菓子はどんなものですか', '和菓子どんなもの 大福とかみたらし団子とか', ' 大福、ですか?', 'はい', ' コンビニですか。よく、行くのですか。'] \n",
      "\n",
      "['コンビニよく行きますね', ' そうなんですね、ちょっと特別なおかしを買うときは近くのお店とか「デパートの地下」とか、利用しますか?', '利用しますね', ' デパートのホームページを見て、キラキラしていて楽しそうと思うのですが、実際はいかがですか?', '実際は人が多くてしんどい所ですね', ' そうなんですか.', ' その中でもおすすめのスイーツはありますか?', '', ' そうなんですか.', 'うん', ' 私の友人はあんこ系が好きだそうです。あずきときなこは、体や肌にいいそうで、よく食べてるそうです・・'] \n",
      "\n",
      "['', ' おばあちゃんがよく家で出してくれていたと言っていました。', 'いいおばあちゃんですね', ' いい思い出だったようです。', '', ' からい食べものとはどんな食べものが好きですか?', '辛い食べ物は  なんか麺も好きやしご飯丼ぶり系も好きです', ' 塩辛いほうですか、トウガラシのからさとかですか?', ' 塩辛いほうですね', ' 具体的な食べ物の名前を教えてください。', '具体的な  オムライスと 牛丼と なんかそんな感じの', ' 牛丼、ですか?', 'はい', ' それは「最近」食べられたんですか?', '最近は食べてないです'] \n",
      "\n",
      "[' そうなんですね、お店ですか、ご自宅ですか?', 'お店ですね', ' なるほど、そうなんですね、', '', ' オムライスそれは「最近」食べられたんですか?', 'オムライスは食べました', ' オムライス、どこで召し上がったのですか・・', 'オムライスは家で食べました', ' そうですか、それは美味しそうですね・・', ' お友達とランチに行ったりしますか?', 'よく行きますね', ' なるほど、どんなところに行きますか?和食ですか洋食ですか?それともはやりのカフェとかですか?', ' 流行りのカフェですね'] \n",
      "\n",
      "[' 例えば?', '例えば あれどこやろ 梅田にある ような 感じ', ' うめだ、ですか?', ' 、ですか?', 'はい', ' うめだ、についてもう少し教えてください・・', ' 、についてもう少し教えてください・・', '梅田は 都会 で すごい服もいっぱいあってご飯屋さんも あって 駅があって栄えてるような場所です', ' 楽しそうですね。たくさんおしゃべりをすると、楽しくて、時間を忘れることがありますよね。', 'ありますね'] \n",
      "\n",
      "[' 楽しい話しをして、笑うと、体にもいいと聞いたことがあります。', '聞いたことあります', ' 、すごくいいと思います。', 'そうですね', ' ありがとうございました・・それではつぎの話題にうつりたいとおもいます。', '', ' 休日は家で過ごすほうが多いですか?外出することが多いですか?', '外出することのほうが多いです', ' そとで過ごすときはスポーツをしたりしますか・・', 'スポーツはあんまりしないです'] \n",
      "\n",
      "[' ショッピングはどちらに行くのですか?', 'ショッピングは  家の近くか 梅田まで出るかどっちかです', ' なるほど、梅田、ですか?', 'はい', ' ありがとうございました・・それではつぎの話題にうつりたいとおもいます。', ' それでは少し「音楽」について話しましょう!', '', ' 聞くとしたら、邦楽,洋楽,クラシックなどどんなジャンルを聞きますか?', ' 邦楽ですね', ' ご自身が好きな、歌手やきょくってありますか?', 'back numberと 平井堅と ミスチルと ゆずと なんかそんな感じです', ' バックナンバー、平井堅、ミスチル、、ですか?', 'はい', ' 特に好きな人は', '特に好きな人は今一番きてるのは平井堅です', ' 平井堅、ですか?', ' 平井堅、についてもう少し教えてください・・'] \n",
      "\n",
      "[' う人です', ' そうなんですね、', ' 私の友人は、カラオケで歌うために、何回もリピートしてその歌を流します。', '', ' カラオケは好きですか?', 'カラオケ好きですね', ' カラオケでよくなにをうたうのですか?', 'よく歌うのは あいみょん と back numberと バラバラです', ' そうなんですね、', ' 最近はひとりカラオケもありますが、カラオケに行くときは「友人」といったりしますか?'] \n",
      "\n",
      "['友人としか行ったことないですね', ' そうですよね、もりあがりそうですね', '', ' コンサートとかには行きますか?', 'コンサートは行かないです', ' そうなんですね、', ' がっきは何か演奏するのですか。', '楽器はもう音楽会以来弾いたことないです', ' そうなんですね、ありがとうございました・・', ' それではつぎの話題にうつりたいとおもいます。', '', ' それでは少し「テレビ」の話をしましょう!'] \n",
      "\n",
      "['', ' さいきんドラマは見ましたか?', 'ドラマ見ました', ' もし,おすすめのドラマがあったら教えてください。', 'マリーゴールド', ' そのドラマはどんな内容なんですか?', '手のひら 主人公のなんか どうしたらいいんやろ 主人公が 倒れてる人と手を合わせると 未来が見えてしまってその未来を変えようと頑張るお話', ' 面白そうですね。そのドラマのどういったところが好きなんですか?', ' すごいきれいな 終わり方やったからです ', ' なるほど、そうなんですね、', ' インターネットの動画配信サービスを利用されたりするのですか。', 'はい', ' 私の知り合いは,見逃したドラマをインターネットの動画配信サービスを利用してみると言っていました。', 'たまにします'] \n",
      "\n",
      "[' なるほど、ユーチューブを見るのも楽しそうですね。', 'そうですね 面白いです', ' 私も時間のある時はユーチューブをみますよ。', '見るんですね', ' 番組名は言えないのですが、', ' 今のこどもたちは、テレビをみずに、ユーチューブなどのネット配信の動画ばかりを見ているみたいですね。', 'そうですね', ' 選択肢がふえますね。', 'そうですね', ' ありがとうございました・・それではつぎの話題にうつりたいとおもいます。'] \n",
      "\n",
      "[' それでは「旅行」について話しましょう', '', ' さいきん旅行には行きましたか?', '最近は沖縄に行きました', ' 沖縄、ですか?', 'はい', ' 沖縄、で,とても楽しかったことを教えてもらっていいですか?', '一番楽しか ったのは  ご飯', ' ごはん、ですか?', 'はい', ' 沖縄、で,美味しい食べ物はたべましたか・・', '美味しい食べ物食べました', ' とくに美味しかったものを教えていただいていいですか?', ' 海ぶどう', ' うみぶどうとは'] \n",
      "\n",
      "['海ぶどうとは 海藻 海藻 です', ' 階層なんですか', 'はい', ' ほかにはありましたか', 'タコライス', ' タコライス、ですか?', 'はい', ' タコライス、についてもう少し教えてください・・', 'ご飯の上に なん か味の付いたパラパラの お肉が乗ってて 卵乗ってたような気が そんな 丼ぶりです', ' それは、美味しそうですね。', ' 美味しかったです', ' ほかには何か面白いことはありましたか?', ' シュノーケリング しました'] \n",
      "\n",
      "[' シューの毛リング、ですか?', ' はい', ' 、具体的に教えてもらえますか?', 'ゴーグルを着けて 海の中を潜るんですけど 魚が 見えて きれいでした', ' お魚とか海の中はキレかったですか', 'きれかったです', ' すごい!面白い体験をされましたね!', '', ' 海外旅行に、興味はありますか?', 'そうですね ありますね', ' とくに、どの国に興味がありますか?', ' 興味がイタリア', ' イタリア、ですか?', 'はい', ' 都市はどこですか', '都市 あんま考えてないです'] \n",
      "\n",
      "[' 例えば?世界遺産とか、', ' 何があるのか 建物がきれいかなみたいなイメージだけです', ' なるほど、そうなんですね、', '', ' 食べ物はおいしいらしいですよ', '', ' バスタとかピザとか', '', ' 貴重な体験談をありがとうございました。', '', ' それでは最後の質問です。', '', ' 近い将来、私のような「エーアイ」を利用してみたいですか?', '特に 思わないです'] \n",
      "\n"
     ]
    }
   ],
   "source": [
    "topic_gen = topic_generator(\n",
    "    transcript_generator('data/golden_transcripts/1911F2002.jsonl'),\n",
    "    threshold=0.2,\n",
    "    max_utterances=50,\n",
    "    min_utterances=10,\n",
    "    delay=3,\n",
    "    n_components=5\n",
    ")\n",
    "\n",
    "for topic in topic_gen:\n",
    "    print(topic, '\\n')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "30f13550-c7d6-45aa-81bc-feb1ff89958e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6496319770812988"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = [' これから本番の収録を開始します。', ' はじめまして・・私の名前は「メイ」です。「対話の実験」の手伝いをしています。今日はよろしくお願いします。', 'よろしくお願いします', ' きょうはここまでなにで来られましたか?乗り物は乗りましたか?', 'そうですね 電車で 来て歩いて来ました', ' ここに来るまで迷いませんでしたか・・', 'ここに来るまでは人に教えてもらったので 迷いませんでした', ' 大学の中でも、たてものが奥にあるので、みなさん来るのが「たいへん」でしたとよく言われます・・', '(F あー)そうなんですか 確かに奥にありました', ' きょうは来ていただいてありがとうございます!', ' それでは「食べ物」について話しましょう!', '(F はい)', ' 甘いものはお好きですか?', '甘いものは洋菓子じゃなくて和菓子のほうが好きですね', ' 普段はどこであまいものを買いますか?', '普段はいやあコンビニが多いですね', ' 和菓子はどんなものですか']\n",
    "b = ['和菓子どんなもの 大福とかみたらし団子とか', ' 大福、ですか?', 'はい', ' コンビニですか。よく、行くのですか。', 'コンビニよく行きますね', ' そうなんですね、ちょっと特別なおかしを買うときは近くのお店とか「デパートの地下」とか、利用しますか?', '(F あー)利用しますね', ' デパートのホームページを見て、キラキラしていて楽しそうと思うのですが、実際はいかがですか?', '実際は人が多くてしんどい所ですね', ' そうなんですか.', ' その中でもおすすめのスイーツはありますか?', '(F えー) は なんかケーキ (D わか)', ' そうなんですか.', 'うん', ' 私の友人はあんこ系が好きだそうです。あずきときなこは、体や肌にいいそうで、よく食べてるそうです・・', '(F ふーん) (F へー)', ' おばあちゃんがよく家で出してくれていたと言っていました。', '(F えー)いいおばあちゃんですね', ' いい思い出だったようです。', '(F はあ)', ' からい食べものとはどんな食べものが好きですか?', '辛い食べ物は (F うーん) なんか麺も好きやしご飯丼ぶり系も好きです', ' 塩辛いほうですか、トウガラシのからさとかですか?', '(D し) 塩辛いほうですね', ' 具体的な食べ物の名前を教えてください。', '具体的な (F えー) オムライスと 牛丼と なんかそんな感じの', ' 牛丼、ですか?', 'はい', ' それは「最近」食べられたんですか?', '最近は食べてないです', ' そうなんですね、お店ですか、ご自宅ですか?', 'お店ですね', ' なるほど、そうなんですね、', '(F はい)', ' オムライスそれは「最近」食べられたんですか?', 'オムライスは食べました', ' オムライス、どこで召し上がったのですか・・', 'オムライスは家で食べました', ' そうですか、それは美味しそうですね・・', ' お友達とランチに行ったりしますか?', 'よく行きますね', ' なるほど、どんなところに行きますか?和食ですか洋食ですか?それともはやりのカフェとかですか?', '(D よう) 流行りのカフェですね', ' 例えば?', '例えば あれどこやろ 梅田にある ような 感じ', ' うめだ、ですか?', ' 、ですか?']\n",
    "calc_similarity('\\n'.join(a[:2]), '\\n'.join(b[:3]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "426f4e80-48f1-43fd-8348-d716fa219f71",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[2, 3]"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(gen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "83ec7165-ef46-4c57-8348-8940006fc8ac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 2]"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[1,2,3,4][:-2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b64c8e5a-7614-484b-82f5-b14e8a192cc5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
